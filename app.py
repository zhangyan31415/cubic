"""
ä¸»ç¨‹åºï¼šå…¨è‡ªåŠ¨é­”æ–¹è¯†åˆ«ä¸å¼•å¯¼ç³»ç»Ÿ
YOLO11åˆ†å‰²æ¨¡å‹ â†’ ç²¾ç¡®æ£€æµ‹ â†’ è¯†åˆ«çŠ¶æ€ â†’ æ±‚è§£ â†’ 3Dç®­å¤´æŒ‡å¼•
"""
import cv2
import numpy as np
import time
import subprocess
import threading
from typing import Optional

from src.detectors.roboflow_detector import RoboflowRubikDetector
from src.core.tracker import SimpleTracker
from src.core.pose import PoseEstimator
from src.core.state import StateManager
from src.core.solver import RubikSolver
from src.core.overlay import OverlayRenderer
from src.core.mini_cube_hud import MiniCubeHUD

# ä¸­æ–‡ç»˜å­—å·¥å…·
from PIL import Image, ImageDraw, ImageFont

def speak(text):
    """å¼‚æ­¥è¯­éŸ³æ’­æŠ¥ï¼ˆå¸¦é˜²æŠ–ï¼Œé¿å…å›éŸ³ï¼‰"""
    # é˜²æŠ–ï¼šåŒä¸€å¥è¯2ç§’å†…ä¸é‡å¤
    now = time.time()
    
    if not hasattr(speak, '_last_text'):
        speak._last_text = None
        speak._last_time = 0
    
    # å¦‚æœæ˜¯åŒä¸€å¥è¯ä¸”æ—¶é—´é—´éš”å¤ªçŸ­ï¼Œè·³è¿‡
    if speak._last_text == text and (now - speak._last_time) < 2.0:
        return
    
    speak._last_text = text
    speak._last_time = now
    
    def _speak():
        try:
            subprocess.run(['say', '-v', 'Ting-Ting', text], check=False, timeout=3)
        except Exception:
            pass
    
    threading.Thread(target=_speak, daemon=True).start()

def put_text_cn(img_bgr, text, xy=(20, 40), font_size=24, color=(0, 255, 0)):
    """ä¸­æ–‡æ–‡å­—ç»˜åˆ¶"""
    font_candidates = (
        "PingFang.ttc", "STHeiti Medium.ttc", "Hiragino Sans GB.ttc",
        "NotoSansCJK-Regular.ttc", "SimSun.ttc", "Microsoft YaHei.ttf"
    )
    font = None
    for fp in font_candidates:
        try:
            font = ImageFont.truetype(fp, font_size)
            break
        except Exception:
            continue
    
    if font is None:
        cv2.putText(img_bgr, text.encode('ascii', 'ignore').decode('ascii'),
                   xy, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        return img_bgr
    
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img_rgb)
    draw = ImageDraw.Draw(pil_img)
    draw.text(xy, text, font=font, fill=(color[2], color[1], color[0]))
    return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

def move_to_cn(move: str) -> str:
    """ç§»åŠ¨æŒ‡ä»¤è½¬ä¸­æ–‡"""
    if not move:
        return ""
    
    face_map = {'U': 'ä¸Š', 'D': 'ä¸‹', 'L': 'å·¦', 'R': 'å³', 'F': 'å‰', 'B': 'å'}
    face = face_map.get(move[0], move[0])
    
    if len(move) > 1:
        if move[1] == "'":
            return f"{face}é¢é€†æ—¶é’ˆ90Â°"
        elif move[1] == '2':
            return f"{face}é¢180Â°"
    
    return f"{face}é¢é¡ºæ—¶é’ˆ90Â°"

class RubikAutoGuide:
    """å…¨è‡ªåŠ¨é­”æ–¹å¼•å¯¼ç³»ç»Ÿ"""
    
    def __init__(self, camera_id: int = 0):
        self.cap = cv2.VideoCapture(camera_id)
        
        # è·å–ç”»é¢å°ºå¯¸
        ret, frame = self.cap.read()
        if not ret:
            raise RuntimeError("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        h, w = frame.shape[:2]
        
        # åˆå§‹åŒ–ç›¸æœºå‚æ•°ï¼ˆæ”¹è¿›ç‰ˆï¼šåŒºåˆ†fxå’Œfyï¼‰
        # TODO: ä½¿ç”¨æ£‹ç›˜æ ¼æ ‡å®šè·å¾—çœŸå®å†…å‚ä»¥æé«˜PnPç²¾åº¦
        fx = w * 0.9  # æ¨ªå‘ç„¦è·
        fy = h * 0.9  # çºµå‘ç„¦è·
        cx = w / 2.0  # ä¸»ç‚¹x
        cy = h / 2.0  # ä¸»ç‚¹y
        self.camera_matrix = np.array([
            [fx, 0, cx],
            [0, fy, cy],
            [0, 0, 1]
        ], dtype=np.float32)
        self.dist_coeffs = np.zeros(5, dtype=np.float32)
        print(f"ğŸ“· ç›¸æœºå†…å‚: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}")
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        # ä½¿ç”¨YOLO11åˆ†å‰²æ¨¡å‹ï¼ˆç²¾ç¡®è½®å»“æ£€æµ‹ + é«˜ç²¾åº¦è¯†åˆ«ï¼‰
        from src.detectors.roboflow_detector import LocalYOLODetector
        import torch
        
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        if torch.backends.mps.is_available():
            device = 'mps'
            half = False  # MPSä¸æ”¯æŒFP16
        elif torch.cuda.is_available():
            device = '0'
            half = True
        else:
            device = 'cpu'
            half = False
        
        self.detector = LocalYOLODetector(
            model_path="models/rubik_cube_yolo11_seg.pt",
            device=device,
            half=half
        )
        # YOLO11-seg æ¨¡å‹ç‰¹æ€§ï¼š
        # âœ“ mAP50: 97.9% (æ‰€æœ‰é¢œè‰²è¯†åˆ«ç‡ > 96%)
        # âœ“ æ¨ç†é€Ÿåº¦: 0.9ms/å¼  (æ¯”YOLOv8å¿«30%)
        # âœ“ æ”¯æŒç²¾ç¡®åˆ†å‰²ï¼šè¿”å›è½®å»“ç‚¹è€Œéç®€å•è¾¹ç•Œæ¡†
        # âœ“ æ¨¡å‹å¤§å°: 45.2MB (è½»é‡é«˜æ•ˆ)
        
        # è‰²å—ç±»åˆ«æ˜ å°„ï¼ˆæ ¹æ®è®­ç»ƒæ•°æ®ï¼‰
        self.facelet_classes = {
            0: 'Blue',
            1: 'Center', 
            2: 'Face',
            3: 'Green',
            4: 'Orange',
            5: 'Red',
            6: 'White',
            7: 'Yellow'
        }
        
        # é¢åç§°åˆ°ç´¢å¼•çš„æ˜ å°„
        self.FACE_TO_IDX = {'U':0, 'R':1, 'F':2, 'D':3, 'L':4, 'B':5}
        
        self.current_facelets = []  # å½“å‰æ£€æµ‹åˆ°çš„è‰²å—
        self.frame_id = 0  # å¸§è®¡æ•°å™¨ï¼ˆç”¨äºæ£€æµ‹åˆ†é¢‘ï¼‰
        
        self.tracker = SimpleTracker()
        self.pose_estimator = PoseEstimator(self.camera_matrix, self.dist_coeffs)
        # YOLO11ç›´æ¥è¿”å›é¢œè‰²ï¼Œä¸éœ€è¦é¢å¤–çš„é¢œè‰²è¯†åˆ«å™¨
        self.state_manager = StateManager()
        self.solver = RubikSolver()
        self.overlay = OverlayRenderer(self.camera_matrix, self.dist_coeffs)
        self.hud = MiniCubeHUD(size=220)  # 3Dè¿·ä½ é­”æ–¹HUD
        
        # çŠ¶æ€å˜é‡
        self.current_bbox = None
        self.current_rvec = None
        self.current_tvec = None
        self.last_rvec = None  # ä¿å­˜ä¸Šä¸€å¸§çš„rvec
        self.last_tvec = None
        self._last_completeness = 0.0  # ä¸Šæ¬¡çš„å®Œæ•´åº¦ï¼ˆç”¨äºæ£€æµ‹å˜åŒ–ï¼‰
        self.last_solve_time = 0
        self.last_move_time = 0
        self.move_index = 0
        self.solution_moves = []
        self.last_state_string = None
        self._last_move_spoken = None  # ä¸Šæ¬¡æ’­æŠ¥çš„æ­¥éª¤ï¼ˆé˜²é‡å¤ï¼‰
        self._last_color_info = None  # ä¸Šæ¬¡è¯†åˆ«çš„é¢œè‰²ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        self.stable_frames = 0
        
        # æ€§èƒ½ç»Ÿè®¡
        self.fps_counter = 0
        self.fps_time = time.time()
        self.current_fps = 0
        
        # é¢œè‰²-é¢çš„åŒå‘æ˜ å°„ï¼ˆé€šè¿‡â€œä¸­å¿ƒå—â€åœ¨çº¿è‡ªæ ¡å‡†ï¼‰
        # face_to_color: 'U'|'D'|'L'|'R'|'F'|'B' -> 'White'|'Yellow'|...
        # color_to_face: é¢œè‰² -> é¢ï¼ˆå½“å…­è‰²éƒ½ç¡®å®šåï¼Œåˆ†ç±»å°†ä¾èµ–æ­¤æ˜ å°„ä»¥é¿å…æŠ–åŠ¨ï¼‰
        self.face_to_color = {}
        self.color_to_face = {}
        
        # ä½å§¿å¹³æ»‘ï¼ˆå‡å°3D HUD æŠ–åŠ¨ï¼‰
        self.rvec_smooth = None
        self.rvec_smooth_alpha = 0.25  # ä½é€šæ»¤æ³¢æƒé‡ï¼ˆ0~1ï¼Œè¶Šå¤§è¶Šå¿«è·Ÿéšï¼‰
    
    def _select_face_cluster(self, detections):
        """ä»è‰²å—æ£€æµ‹ç»“æœä¸­é€‰å‡ºæœ€å¯èƒ½å±äºåŒä¸€é¢çš„èšç±»ï¼ˆæœ€å¤š9ä¸ªï¼‰ã€‚
        detections: List[dict] - æ¯ä¸ªdictåŒ…å« x1,y1,x2,y2,conf,cls,points(å¯é€‰)
        è¿”å›: è¯¥èšç±»çš„å­åˆ—è¡¨ï¼ˆä¿æŒåŸå­—æ®µï¼‰ï¼Œæˆ– None
        """
        if not detections:
            return None
        # è®¡ç®—ä¸­å¿ƒå’Œå°ºå¯¸
        items = []
        for det in detections:
            x1, y1, x2, y2 = det['x1'], det['y1'], det['x2'], det['y2']
            cx = 0.5 * (x1 + x2)
            cy = 0.5 * (y1 + y2)
            size = 0.5 * ((x2 - x1) + (y2 - y1))
            items.append((cx, cy, size))
        if not items:
            return None
        sizes = [s for _, _, s in items]
        med_size = max(8.0, float(np.median(sizes)))
        eps = med_size * 1.8
        n = len(items)
        # æ„å»ºåŸºäºè·ç¦»çš„è¿é€šåˆ†é‡
        visited = [False] * n
        components = []
        for i in range(n):
            if visited[i]:
                continue
            # BFS
            queue = [i]
            visited[i] = True
            comp = [i]
            while queue:
                u = queue.pop(0)
                ux, uy, us = items[u]
                for v in range(n):
                    if visited[v]:
                        continue
                    vx, vy, vs = items[v]
                    # é˜ˆå€¼ä½¿ç”¨ä¸¤è€…å°ºå¯¸çš„è¾ƒå¤§å€¼
                    th = 1.8 * max(us, vs)
                    if (ux - vx) ** 2 + (uy - vy) ** 2 <= th ** 2:
                        visited[v] = True
                        queue.append(v)
                        comp.append(v)
            components.append(comp)
        # é€‰æ‹©æœ€å¤§ä¸”å½¢çŠ¶æ›´æ¥è¿‘3x3çš„ç»„ä»¶
        best_comp = None
        best_score = -1e9
        for comp in components:
            if len(comp) < 5:
                continue
            # è®¡ç®—è¾¹ç•Œæ¡†ä¸é•¿å®½æ¯”ã€å°ºå¯¸æ–¹å·®
            xs = [detections[i]['x1'] for i in comp] + [detections[i]['x2'] for i in comp]
            ys = [detections[i]['y1'] for i in comp] + [detections[i]['y2'] for i in comp]
            w = max(xs) - min(xs)
            h = max(ys) - min(ys)
            aspect = (w + 1e-6) / (h + 1e-6)
            size_std = float(np.std([items[i][2] for i in comp]))
            # è¯„åˆ†ï¼šæ•°é‡ä¼˜å…ˆï¼Œå…¶æ¬¡å½¢çŠ¶æ¥è¿‘æ­£æ–¹ä¸å°ºå¯¸ä¸€è‡´æ€§
            score = len(comp) * 2.0 - 0.6 * abs(aspect - 1.0) - 0.02 * size_std
            if score > best_score:
                best_score = score
                best_comp = comp
        if not best_comp:
            return None
        # åªå–æœ€å¤š9ä¸ªï¼Œä¼˜å…ˆé è¿‘ä¸­å¿ƒçš„
        cx_all = float(np.mean([items[i][0] for i in best_comp]))
        cy_all = float(np.mean([items[i][1] for i in best_comp]))
        best_comp_sorted = sorted(best_comp, key=lambda i: (items[i][0]-cx_all)**2 + (items[i][1]-cy_all)**2)
        keep_idx = best_comp_sorted[:min(9, len(best_comp_sorted))]
        return [detections[i] for i in keep_idx]

    def _order_tl_tr_br_bl(self, pts):
        """å°†ç‚¹æ’åºä¸º TL, TR, BR, BLã€‚pts: Nx2 æˆ–åˆ—è¡¨ã€‚"""
        pts = np.asarray(pts, dtype=np.float32)
        if pts.ndim != 2 or pts.shape[1] != 2 or pts.shape[0] < 4:
            return None
        if pts.shape[0] > 4:
            rect = cv2.minAreaRect(pts)
            pts = cv2.boxPoints(rect).astype(np.float32)
        s = pts.sum(1)
        d = np.diff(pts, axis=1).ravel()
        tl = pts[np.argmin(s)]; br = pts[np.argmax(s)]
        tr = pts[np.argmin(d)]; bl = pts[np.argmax(d)]
        return np.stack([tl, tr, br, bl], axis=0)

    def _outer_quad_from_facelets(self, detections, expand=1.06):
        if not detections:
            return None
        corners = []
        for det in detections:
            x1, y1, x2, y2 = det['x1'], det['y1'], det['x2'], det['y2']
            corners.extend([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])
        quad = self._order_tl_tr_br_bl(corners)
        if quad is None:
            return None
        c = quad.mean(0)
        quad = c + (quad - c) * float(expand)
        return quad

    def _warp_face_to_square(self, roi, quad_xy, out_size=300):
        if isinstance(quad_xy, np.ndarray) and quad_xy.shape[0] == 4:
            quad = quad_xy.astype(np.float32)
        else:
            quad = np.array(self._order_tl_tr_br_bl(quad_xy), dtype=np.float32)
        dst = np.float32([[0,0], [out_size-1,0], [out_size-1,out_size-1], [0,out_size-1]])
        H = cv2.getPerspectiveTransform(quad, dst)
        face = cv2.warpPerspective(roi, H, (out_size, out_size), flags=cv2.INTER_LINEAR)
        return face, H

    def _build_uniform_quads(self, out_size=300, margin=20):
        """åœ¨ out_sizeÃ—out_size ç©ºé—´å†…æ„é€  3Ã—3 ç­‰åˆ†ç½‘æ ¼çš„ 9 ä¸ªå››è¾¹å½¢ï¼ˆTL,TR,BR,BLï¼‰ã€‚"""
        cs = out_size // 3
        quads = []
        for i in range(3):
            for j in range(3):
                x1 = j * cs + margin
                y1 = i * cs + margin
                x2 = (j + 1) * cs - margin
                y2 = (i + 1) * cs - margin
                quad = np.array([[x1,y1],[x2,y1],[x2,y2],[x1,y2]], np.int32)
                quads.append(quad)
        return quads

    def detect_and_track(self, frame: np.ndarray) -> Optional[tuple]:
        """æ£€æµ‹å’Œè·Ÿè¸ªé­”æ–¹ï¼ˆYOLO11å¾ˆå¿«ï¼Œæ¯å¸§æ£€æµ‹ï¼‰"""
        self.frame_id += 1
        
        # YOLO11æ¨ç†åªéœ€0.9msï¼Œæ¯å¸§éƒ½æ£€æµ‹ï¼
        detections = self.detector.detect(frame, conf_threshold=0.5)
        
        if not detections:
            self.tracker.update(None)
            self.current_facelets = []
            self.current_bbox = None
            return None
        
        # ä¿å­˜æ£€æµ‹åˆ°çš„è‰²å—ï¼ˆç”¨äºçŠ¶æ€è¯†åˆ«ï¼‰
        self.current_facelets = detections
        
        # å…ˆé€‰å‡ºæœ€å¯èƒ½çš„åŒä¸€é¢èšç±»
        cluster = self._select_face_cluster(detections)
        src_for_bbox = cluster if cluster else detections
        x1 = min(det['x1'] for det in src_for_bbox)
        y1 = min(det['y1'] for det in src_for_bbox)
        x2 = max(det['x2'] for det in src_for_bbox)
        y2 = max(det['y2'] for det in src_for_bbox)
        
        # æ‰©å±•è¾¹ç•Œ
        margin = 30
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(frame.shape[1], x2 + margin)
        y2 = min(frame.shape[0], y2 + margin)
        
        bbox = (x1, y1, x2, y2)
        self.tracker.update(bbox)
        self.current_bbox = bbox
        return bbox
    
    def _visible_face_from_pose(self, rvec) -> Optional[str]:
        """æ ¹æ®ä½å§¿åˆ¤æ–­å½“å‰å¯è§çš„é¢"""
        if rvec is None:
            return None
        
        R, _ = cv2.Rodrigues(rvec)
        
        # é­”æ–¹ç‰©ä½“åæ ‡ç³»çš„6ä¸ªé¢æ³•å‘ï¼ˆä¸PnPæ¨¡å‹ä¸€è‡´ï¼‰
        FACE_NORMALS_OBJ = {
            'F': np.array([0, 0,  1.0]),   # æ­£ Z
            'B': np.array([0, 0, -1.0]),
            'U': np.array([0, 1.0, 0]),   # æ­£ Y
            'D': np.array([0,-1.0, 0]),
            'R': np.array([1.0, 0, 0]),   # æ­£ X
            'L': np.array([-1.0, 0, 0]),
        }
        
        # æ˜ å°„åˆ°ç›¸æœºåæ ‡ï¼Œzåˆ†é‡æœ€å¤§çš„å°±æ˜¯æ­£å¯¹æ‘„åƒå¤´çš„é¢
        best_face, best_z = None, -1e9
        for label, normal in FACE_NORMALS_OBJ.items():
            n_cam = R @ normal
            z = n_cam[2]
            if z > best_z:
                best_face, best_z = label, z
        
        return best_face
    
    def _draw_axes_debug(self, img, rvec, tvec, K, dist):
        """ç»˜åˆ¶åæ ‡è½´ç”¨äºè°ƒè¯•ï¼ˆXçº¢, Yç»¿, Zè“ï¼‰"""
        axis = np.float32([[0,0,0], [0.03,0,0], [0,0.03,0], [0,0,0.05]])
        pts, _ = cv2.projectPoints(axis, rvec, tvec, K, dist)
        o, x, y, z = [tuple(map(int, p.ravel())) for p in pts]
        cv2.line(img, o, x, (0, 0, 255), 2)  # X çº¢
        cv2.line(img, o, y, (0, 255, 0), 2)  # Y ç»¿
        cv2.line(img, o, z, (255, 0, 0), 2)  # Z è“
    
    # ä¸Šé¢é‡å†™äº†æ’åº/å¤–æ¥å››è§’/warp è¾…åŠ©å‡½æ•°
    
    def _order_facelets_3x3(self, dets):
        """å°†9ä¸ªæ£€æµ‹æ¡†æŒ‰3Ã—3ç©ºé—´ä½ç½®æ’åºï¼ˆTLâ†’BRï¼‰"""
        if len(dets) < 9:
            return None
        
        # è®¡ç®—ä¸­å¿ƒç‚¹
        centers = np.array([[(d['x1']+d['x2'])/2., (d['y1']+d['y2'])/2.] for d in dets[:9]], np.float32)
        mu = centers.mean(0)
        
        # PCAä¸»è½´å’Œæ¬¡è½´
        _, _, Vt = np.linalg.svd(centers - mu)
        ax = Vt[0]  # ä¸»è½´ï¼ˆé€šå¸¸æ˜¯æ¨ªå‘ï¼‰
        ay = Vt[1]  # æ¬¡è½´ï¼ˆé€šå¸¸æ˜¯çºµå‘ï¼‰
        
        # ä¿è¯å³æ‰‹åæ ‡ç³»ï¼ˆå›¾åƒyè½´å‘ä¸‹ï¼‰
        if np.cross(np.append(ax, 0), np.append(ay, 0))[2] < 0:
            ay = -ay
        
        # æŠ•å½±åˆ°ä¸»è½´å’Œæ¬¡è½´
        u = (centers - mu) @ ax  # æ¨ªå‘åæ ‡
        v = (centers - mu) @ ay  # çºµå‘åæ ‡
        
        # åˆ†æˆ3è¡Œ3åˆ—
        row_bounds = np.percentile(v, [33.33, 66.67])
        col_bounds = np.percentile(u, [33.33, 66.67])
        
        rows = np.digitize(v, row_bounds)
        cols = np.digitize(u, col_bounds)
        
        # æ„å»º3Ã—3ç½‘æ ¼
        grid = [[None]*3 for _ in range(3)]
        for i, (r, c) in enumerate(zip(rows, cols)):
            r, c = int(r), int(c)
            if 0 <= r < 3 and 0 <= c < 3:
                if grid[r][c] is None:  # é¿å…é‡å¤
                    grid[r][c] = dets[i]
        
        # æ£€æŸ¥æ˜¯å¦9ä¸ªæ ¼å­éƒ½æœ‰
        if any(grid[r][c] is None for r in range(3) for c in range(3)):
            return None
        
        # å±•å¹³æˆTLâ†’BRé¡ºåº
        return [grid[r][c] for r in range(3) for c in range(3)]
    
    def _rotate_labels_3x3(self, labels, k):
        """æ—‹è½¬3Ã—3æ ‡ç­¾ï¼ˆkÃ—90Â°ï¼Œk=0/1/2/3ï¼‰"""
        g = np.array(labels).reshape(3, 3)
        if k == 0:
            return labels
        elif k == 1:
            g = np.rot90(g, k=-1)  # é¡ºæ—¶é’ˆ90Â°
        elif k == 2:
            g = np.rot90(g, 2)     # 180Â°
        else:
            g = np.rot90(g, 1)      # é€†æ—¶é’ˆ90Â°
        return g.reshape(-1).tolist()
    
    def recognize_current_state(self, frame: np.ndarray, bbox: tuple) -> bool:
        """è¯†åˆ«å½“å‰é­”æ–¹çŠ¶æ€ï¼ˆå®Œæ•´PnPé“¾è·¯ï¼šROIâ†’ç½‘æ ¼â†’ä½å§¿â†’é¢œè‰²ï¼‰"""
        x1, y1, x2, y2 = bbox
        
        # æå–ROI
        roi = frame[y1:y2, x1:x2]
        if roi.size == 0 or roi.shape[0] < 50 or roi.shape[1] < 50:
            return False
        
        # ===== å…³é”®ä¿®å¤ï¼šå…ˆç”¨PoseEstimatoræå–3Ã—3ç½‘æ ¼ =====
        # è¿™æ˜¯PnPçš„å¿…è¦è¾“å…¥ï¼ä¹‹å‰ä¸€ç›´ç¼ºå¤±å¯¼è‡´rvec=None
        grid_quads = self.pose_estimator.detect_face_grid(roi)
        
        if grid_quads is None or len(grid_quads) != 9:
            # è°ƒè¯•ä¿¡æ¯ï¼šä¸ºä»€ä¹ˆæ²¡æ‰¾åˆ°9ä¸ªæ ¼å­
            if grid_quads is None:
                print(f"âš ï¸ æœªæ£€æµ‹åˆ°ç½‘æ ¼ (grid_quads=None)")
            else:
                print(f"âš ï¸ æ£€æµ‹åˆ°{len(grid_quads)}ä¸ªæ ¼å­ï¼Œéœ€è¦9ä¸ª")
            return False
        
        # ===== æ­¥éª¤1ï¼šPnPä½å§¿ä¼°è®¡ =====
        pose_result = self.pose_estimator.estimate_pose_from_grid(
            roi, grid_quads, roi_offset=(x1, y1)
        )
        
        if pose_result is None:
            print("âš ï¸ PnPå¤±è´¥")
            return False
        
        rvec_raw, tvec_raw = pose_result
        
        # ===== æ­¥éª¤2ï¼šä½å§¿å¹³æ»‘ï¼ˆå…³é”®ï¼é¿å…HUDæŠ–åŠ¨ï¼‰ =====
        if self.last_rvec is not None and self.last_tvec is not None:
            # æŒ‡æ•°ç§»åŠ¨å¹³å‡
            alpha = 0.3  # å¹³æ»‘ç³»æ•°
            rvec_raw = (1 - alpha) * self.last_rvec + alpha * rvec_raw
            tvec_raw = (1 - alpha) * self.last_tvec + alpha * tvec_raw
        
        # æ›´æ–°å½“å‰ä½å§¿
        self.current_rvec = rvec_raw
        self.current_tvec = tvec_raw
        self.last_rvec = rvec_raw
        self.last_tvec = tvec_raw
        
        # æ›´æ–°å¹³æ»‘ä½å§¿ï¼ˆç”¨äºHUDæ¸²æŸ“ï¼‰
        if self.rvec_smooth is None:
            self.rvec_smooth = rvec_raw.copy()
        else:
            self.rvec_smooth = (1.0 - self.rvec_smooth_alpha) * self.rvec_smooth + self.rvec_smooth_alpha * rvec_raw
        
        print(f"âœ“ PnPæˆåŠŸ: rvec norm={np.linalg.norm(rvec_raw):.3f}, tvec[2]={tvec_raw[2,0]:.3f}")
        
        # ===== æ­¥éª¤3ï¼šé¢œè‰²è¯†åˆ«ï¼ˆä½¿ç”¨YOLOæ£€æµ‹ç»“æœï¼‰ =====
        cluster = self._select_face_cluster(self.current_facelets)
        if not cluster or len(cluster) < 7:
            # ä½å§¿æœ‰äº†ï¼Œä½†é¢œè‰²ä¿¡æ¯ä¸è¶³ï¼Œè‡³å°‘ä½å§¿å¯ä»¥æ›´æ–°HUD
            return True  # æ”¹ä¸ºTrueï¼Œå› ä¸ºä½å§¿å·²ç»æ›´æ–°äº†
        
        # æŒ‰3Ã—3ç©ºé—´ä½ç½®æ’åº
        nine = self._order_facelets_3x3(cluster)
        if nine is None:
            return True  # ä½å§¿æœ‰æ•ˆï¼Œé¢œè‰²æ’åºå¤±è´¥ï¼Œä»è¿”å›True
        
        # ===== æ­¥éª¤4ï¼šæå–YOLOé¢œè‰²åï¼Œè½¬æ¢æˆé¢œè‰²å­—æ¯ =====
        COLOR_TO_LETTER = {
            'White': 'U',   'Yellow': 'D',  'Red': 'R',
            'Orange': 'L',  'Green': 'F',   'Blue': 'B'
        }
        
        raw_letters = []
        raw_confs = []
        for det in nine:
            cls_id = det.get('cls', -1)
            if 0 <= cls_id < len(self.detector.model.names):
                color_name = self.detector.model.names[cls_id]
                if color_name in COLOR_TO_LETTER:
                    raw_letters.append(COLOR_TO_LETTER[color_name])
                    raw_confs.append(det['conf'])
                else:
                    raw_letters.append('?')
                    raw_confs.append(det['conf'])
            else:
                raw_letters.append('?')
                raw_confs.append(0.0)
        
        # ===== æ­¥éª¤5ï¼šæ‰¾å‡ ä½•ä¸­å¿ƒæœ€è¿‘çš„æ ¼å­ï¼ˆä¸­å¿ƒå—ï¼‰ =====
        centers = np.array([[(d['x1']+d['x2'])/2., (d['y1']+d['y2'])/2.] for d in nine], np.float32)
        geo_center = centers.mean(0)
        dists = ((centers - geo_center)**2).sum(1)
        center_idx = np.argmin(dists)
        center_letter = raw_letters[center_idx]
        
        # å¦‚æœä¸­å¿ƒå—æ˜¯'?'ï¼Œç”¨ä¼—æ•°å¡«å……
        if center_letter == '?':
            from collections import Counter
            counts = Counter([l for l in raw_letters if l != '?'])
            if counts:
                center_letter = counts.most_common(1)[0][0]
        
        # ç”¨ä¸­å¿ƒå—é¢œè‰²å¡«å……æ‰€æœ‰'?'
        raw_letters = [center_letter if l == '?' else l for l in raw_letters]
        
        # ===== æ­¥éª¤6ï¼šç”¨rvecåˆ¤æ–­å¯è§é¢ï¼ˆF/B/U/D/L/Rï¼‰ =====
        # ç”±äºPnPå·²ç»åœ¨å‰é¢å®Œæˆï¼Œè¿™é‡Œç”¨rvecæ¨æ–­ç‰©ç†é¢
        def get_visible_face_from_rvec(rvec):
            """æ ¹æ®rvecåˆ¤æ–­å“ªä¸ªé¢æœå‘ç›¸æœº"""
            R, _ = cv2.Rodrigues(rvec)
            # å®šä¹‰6ä¸ªé¢çš„æ³•å‘é‡ï¼ˆç‰©ä½“åæ ‡ç³»ï¼‰
            face_normals = {
                'F': np.array([0, 0, 1.0]),
                'B': np.array([0, 0, -1.0]),
                'U': np.array([0, 1.0, 0]),
                'D': np.array([0, -1.0, 0]),
                'R': np.array([1.0, 0, 0]),
                'L': np.array([-1.0, 0, 0]),
            }
            # æ‰¾åˆ°zåˆ†é‡æœ€å¤§çš„ï¼ˆæœå‘ç›¸æœºï¼‰
            best_face = None
            best_z = -9999
            for face_label, normal in face_normals.items():
                n_cam = R @ normal
                if n_cam[2] > best_z:
                    best_z = n_cam[2]
                    best_face = face_label
            return best_face
        
        visible_face = get_visible_face_from_rvec(self.current_rvec)
        if visible_face is None:
            visible_face = 'F'  # é»˜è®¤å‰é¢
        
        # ===== æ­¥éª¤7ï¼škÃ—90Â°æœå‘æ ¡æ­£ï¼ˆç®€åŒ–ç‰ˆï¼‰ =====
        # TODO: æ ¹æ®å®é™…æŠ•å½±æ–¹å‘ä¼°è®¡k
        k = 0  # æš‚æ—¶ç®€åŒ–ï¼Œåç»­å¯æ ¹æ®æŠ•å½±æ ¡æ­£
        labels = self._rotate_labels_3x3(raw_letters, k)
        
        # ===== æ­¥éª¤8ï¼šä¿å­˜æ˜¾ç¤ºä¿¡æ¯ =====
        self._last_color_info = {
            'labels': labels,
            'percentages': [(lbl, conf*100) for lbl, conf in zip(labels, raw_confs)],
            'quads': None,
            'H': None,
            'roi_offset': (x1, y1),
            'cluster': nine
        }
        
        # ===== æ­¥éª¤9ï¼šæ›´æ–°StateManagerï¼ˆæŒ‰ç‰©ç†é¢ï¼‰ =====
        face_idx = self.FACE_TO_IDX[visible_face]
        success = self.state_manager.update_face(face_idx, labels, confidence=0.9)
        
        if success:
            # æ˜¾ç¤ºæç¤ºï¼ˆåªåœ¨å®Œæ•´åº¦å˜åŒ–æ—¶æ’­æŠ¥ï¼Œé¿å…é‡å¤ï¼‰
            completeness = self.state_manager.get_completeness()
            
            # åªåœ¨å®Œæ•´åº¦è·¨è¶Šé˜ˆå€¼æ—¶æ’­æŠ¥ä¸€æ¬¡
            if not hasattr(self, '_last_completeness'):
                self._last_completeness = 0.0
            
            if completeness >= 1.0/6 and completeness < 2.0/6 and self._last_completeness < 1.0/6:
                speak("å·²è¯†åˆ«ç¬¬ä¸€é¢ï¼Œè¯·è½¬åŠ¨é­”æ–¹æ‰«æå…¶ä»–é¢")
            elif completeness >= 0.5 and completeness < 0.6 and self._last_completeness < 0.5:
                speak("å·²è¯†åˆ«ä¸‰ä¸ªé¢ï¼Œç»§ç»­")
            elif completeness >= 0.9 and self._last_completeness < 0.9:
                speak("è¯†åˆ«å®Œæˆï¼Œæ­£åœ¨è®¡ç®—è§£æ³•")
            
            self._last_completeness = completeness
        
        return success
    
    def check_move_completion(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å®Œæˆäº†å½“å‰æ­¥éª¤"""
        # è·å–å½“å‰çŠ¶æ€
        current_state = self.state_manager.get_stable_state()
        
        if current_state is None:
            return False
        
        # å¦‚æœçŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼Œå¯èƒ½å®Œæˆäº†æ“ä½œ
        if current_state != self.last_state_string:
            self.stable_frames = 0
            self.last_state_string = current_state
            return False
        
        self.stable_frames += 1
        
        # å¦‚æœçŠ¶æ€ç¨³å®šäº†ä¸€æ®µæ—¶é—´ï¼Œè®¤ä¸ºå®Œæˆäº†æ“ä½œ
        if self.stable_frames > 10:  # çº¦0.3ç§’ï¼ˆ30fpsï¼‰
            return True
        
        return False
    
    def run(self):
        """ä¸»å¾ªç¯"""
        print("=" * 60)
        print("å…¨è‡ªåŠ¨é­”æ–¹è¯†åˆ«ä¸å¼•å¯¼ç³»ç»Ÿ (YOLO11-seg)")
        print("=" * 60)
        print("âœ“ æ¨¡å‹: YOLO11åˆ†å‰²æ¨¡å‹ (mAP50: 97.9%)")
        print("âœ“ æ¨ç†é€Ÿåº¦: ~0.9ms/å¼ ")
        print("æç¤ºï¼šå°†é­”æ–¹æ”¾åœ¨æ‘„åƒå¤´å‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å¹¶å¼•å¯¼")
        print("æŒ‰ ESC é€€å‡º")
        print()
        
        speak("ç³»ç»Ÿå¯åŠ¨ï¼Œè¯·å°†é­”æ–¹æ”¾åœ¨æ‘„åƒå¤´å‰")
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # æ£€æµ‹å’Œè·Ÿè¸ª
            bbox = self.detect_and_track(frame)
            
            # åˆ›å»ºæ˜¾ç¤ºç”»é¢
            display = frame.copy()
            
            if bbox:
                x1, y1, x2, y2 = bbox
                
                # ç»˜åˆ¶æ•´ä½“æ£€æµ‹æ¡†
                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # ç»˜åˆ¶æ¯ä¸ªè‰²å—ï¼ˆæ”¯æŒåˆ†å‰²è½®å»“ï¼‰
                for det in self.current_facelets:
                    bx1, by1, bx2, by2 = det['x1'], det['y1'], det['x2'], det['y2']
                    conf = det['conf']
                    cls_id = det.get('cls', -1)
                    points = det.get('points')
                    
                    # å¦‚æœæœ‰è½®å»“ç‚¹ï¼Œç»˜åˆ¶ç²¾ç¡®è½®å»“ï¼›å¦åˆ™ç»˜åˆ¶çŸ©å½¢
                    if points and len(points) > 2:
                        # ç»˜åˆ¶è½®å»“ï¼ˆè“è‰²ï¼‰
                        pts = np.array(points, np.int32).reshape((-1, 1, 2))
                        cv2.polylines(display, [pts], True, (255, 0, 0), 2)
                        # å¡«å……åŠé€æ˜
                        overlay = display.copy()
                        cv2.fillPoly(overlay, [pts], (255, 0, 0))
                        cv2.addWeighted(overlay, 0.15, display, 0.85, 0, display)
                    else:
                        # ç»˜åˆ¶çŸ©å½¢æ¡†ï¼ˆè“è‰²ï¼‰
                        cv2.rectangle(display, (int(bx1), int(by1)), (int(bx2), int(by2)), (255, 0, 0), 2)
                    
                    # æ˜¾ç¤ºç½®ä¿¡åº¦
                    txt = f"{conf:.2f}"
                    if cls_id >= 0:
                        txt += f"/{cls_id}"
                    cv2.putText(display, txt, (int(bx1), int(by1)-5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
                
                # æ˜¾ç¤ºæ£€æµ‹ä¿¡æ¯ï¼ˆæ£€æµ‹æ˜¯å¦æœ‰åˆ†å‰²è½®å»“ï¼‰
                has_segmentation = any(det.get('points') is not None for det in self.current_facelets)
                seg_info = " (Segmentation)" if has_segmentation else ""
                cv2.putText(display, f"Detected {len(self.current_facelets)} facelets{seg_info}", (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # è¯†åˆ«çŠ¶æ€ï¼ˆæ¯5å¸§æ›´æ–°ä¸€æ¬¡ï¼Œé™ä½CPUè´Ÿæ‹…ï¼‰
                recognized = False
                if self.frame_id % 5 == 0:
                    recognized = self.recognize_current_state(frame, bbox)
                else:
                    # ä½¿ç”¨ä¸Šä¸€å¸§çš„è¯†åˆ«ç»“æœ
                    recognized = hasattr(self, '_last_color_info') and self._last_color_info is not None
                
                # ç›´æ¥åœ¨æ¯ä¸ªæ£€æµ‹æ¡†ä¸Šæ˜¾ç¤ºYOLOçš„åŸå§‹é¢œè‰²ï¼ˆç®€åŒ–é€»è¾‘ï¼‰
                for det in self.current_facelets:
                    cls_id = det.get('cls', -1)
                    if cls_id >= 0 and cls_id < len(self.detector.model.names):
                        color_name = self.detector.model.names[cls_id]
                        conf = det['conf']
                        
                        # è·å–æ£€æµ‹æ¡†ä¸­å¿ƒ
                        bx1, by1, bx2, by2 = det['x1'], det['y1'], det['x2'], det['y2']
                        center_x = int((bx1 + bx2) / 2)
                        center_y = int((by1 + by2) / 2)
                        
                        # ç»˜åˆ¶æ ‡ç­¾ï¼ˆç®€å•æ–‡å­—ï¼Œä¸è¦èƒŒæ™¯æ¡†ï¼‰
                        text = f"{color_name}"
                        cv2.putText(display, text, (center_x - 20, center_y),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)
                        cv2.putText(display, text, (center_x - 20, center_y),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 200, 0), 1, cv2.LINE_AA)
                
                # ç»˜åˆ¶åæ ‡è½´ç”¨äºè°ƒè¯•
                if self.current_rvec is not None and self.current_tvec is not None:
                    # åœ¨ROIä¸Šç»˜åˆ¶åæ ‡è½´
                    roi_display = display[y1:y2, x1:x2].copy()
                    cv2.drawFrameAxes(
                        roi_display,
                        self.camera_matrix,
                        self.dist_coeffs,
                        self.current_rvec,
                        self.current_tvec,
                        0.05,  # è½´é•¿åº¦
                        thickness=2
                    )
                    display[y1:y2, x1:x2] = roi_display
                
                if recognized and self.current_rvec is not None:
                    # è·å–ä¸‹ä¸€æ­¥æ“ä½œ
                    next_move = self.solver.get_next_move()
                    
                    # å¦‚æœæœ‰è§£ï¼Œæ˜¾ç¤º3Då åŠ å’Œç®­å¤´
                    if next_move:
                        display = self.overlay.render_overlay(
                            display, self.current_rvec, self.current_tvec, next_move
                        )
                        
                        # æ˜¾ç¤ºæ–‡å­—æç¤º
                        move_cn = move_to_cn(next_move)
                        tip = f"ä¸‹ä¸€æ­¥: {next_move} - {move_cn}"
                        display = put_text_cn(display, tip, (20, 40), 
                                             font_size=28, color=(0, 255, 255))
                    else:
                        # å°è¯•æ±‚è§£
                        stable_state = self.state_manager.get_stable_state()
                        if stable_state and stable_state != self.last_state_string:
                            print(f"æ£€æµ‹åˆ°æ–°çŠ¶æ€ï¼Œå°è¯•æ±‚è§£...")
                            moves = self.solver.solve(stable_state)
                            if moves:
                                self.solution_moves = moves
                                self.move_index = 0
                                self.last_state_string = stable_state
                                self._last_move_spoken = None  # é‡ç½®
                                print(f"æ±‚è§£æˆåŠŸï¼å…± {len(moves)} æ­¥")
                                speak(f"æ±‚è§£æˆåŠŸï¼Œå…±{len(moves)}æ­¥")
                                
                                # æ’­æŠ¥ç¬¬ä¸€æ­¥ï¼ˆé˜²æŠ–æœºåˆ¶ä¼šè‡ªåŠ¨å¤„ç†é—´éš”ï¼‰
                                if moves:
                                    speak(f"ç¬¬ä¸€æ­¥ï¼Œ{move_to_cn(moves[0])}")
                                    self._last_move_spoken = 0
                            else:
                                display = put_text_cn(display, "çŠ¶æ€ä¸å¯è§£ï¼Œè¯·é‡æ–°æ‘†æ”¾", 
                                                     (20, 40), color=(0, 0, 255))
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆå½“å‰æ­¥éª¤
                    if self.check_move_completion() and self.solver.get_next_move():
                        self.solver.advance_move()
                        self.move_index += 1
                        self.stable_frames = 0
                        
                        # æ’­æŠ¥ä¸‹ä¸€æ­¥ï¼ˆåªåœ¨æ­¥éª¤å˜åŒ–æ—¶æ’­æŠ¥ï¼‰
                        next_move = self.solver.get_next_move()
                        if next_move:
                            if self._last_move_spoken != self.move_index:
                                speak(f"ç¬¬{self.move_index+1}æ­¥ï¼Œ{move_to_cn(next_move)}")
                                self._last_move_spoken = self.move_index
                        else:
                            # åªåœ¨ç¬¬ä¸€æ¬¡å®Œæˆæ—¶æ’­æŠ¥
                            if self._last_move_spoken != -1:
                                speak("å®Œæˆï¼é­”æ–¹å·²è¿˜åŸ")
                                self._last_move_spoken = -1
                            print("âœ“ é­”æ–¹å·²è¿˜åŸï¼")
                else:
                    display = put_text_cn(display, "æ­£åœ¨è¯†åˆ«é­”æ–¹çŠ¶æ€...", 
                                         (20, 40), color=(255, 255, 0))
            else:
                display = put_text_cn(display, "æœªæ£€æµ‹åˆ°é­”æ–¹ï¼Œè¯·å°†é­”æ–¹æ”¾åœ¨æ‘„åƒå¤´å‰", 
                                     (20, 40), color=(0, 0, 255))
            
            # æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯
            completeness = self.state_manager.get_completeness()
            info_text = f"çŠ¶æ€å®Œæ•´åº¦: {completeness*100:.1f}%"
            if self.solution_moves:
                info_text += f" | å‰©ä½™æ­¥éª¤: {len(self.solver.get_remaining_moves())}"
            display = put_text_cn(display, info_text, (20, 80), 
                                 font_size=20, color=(255, 255, 255))
            
            # è®¡ç®—FPSï¼ˆç®€åŒ–æ˜¾ç¤ºï¼Œä¸ç”¨æ…¢çš„ä¸­æ–‡ç»˜å­—ï¼‰
            self.fps_counter += 1
            if time.time() - self.fps_time > 1.0:
                self.current_fps = self.fps_counter
                self.fps_counter = 0
                self.fps_time = time.time()
            
            # æ˜¾ç¤ºFPSï¼ˆç”¨ç®€å•çš„cv2.putTextï¼‰
            if hasattr(self, 'current_fps'):
                fps_text = f"FPS: {self.current_fps}"
                cv2.putText(display, fps_text, (display.shape[1]-120, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # æ¸²æŸ“3Dè¿·ä½ é­”æ–¹HUDï¼ˆä½¿ç”¨å¹³æ»‘åçš„ä½å§¿ï¼‰
            r_for_hud = self.rvec_smooth if self.rvec_smooth is not None else self.current_rvec
            display = self.hud.render(display, r_for_hud, self.state_manager)
            
            cv2.imshow("AI Rubik Auto Guide", display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
        
        self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.cap.release()
        cv2.destroyAllWindows()
        print("\nç¨‹åºç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")

if __name__ == "__main__":
    try:
        app = RubikAutoGuide(camera_id=0)
        app.run()
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
